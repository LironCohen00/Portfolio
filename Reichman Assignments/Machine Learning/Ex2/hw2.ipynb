{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bd0516e7cb654f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercise 2: Decision Trees\n",
    "\n",
    "In this assignment you will implement a Decision Tree algorithm as learned in class.\n",
    "\n",
    "## Do not start the exercise until you fully understand the submission guidelines.\n",
    "\n",
    "* The homework assignments are executed automatically. \n",
    "* Failure to comply with the following instructions will result in a significant penalty. \n",
    "* Appeals regarding your failure to read these instructions will be denied. \n",
    "* Kindly reminder: the homework assignments contribute 50% of the final grade.\n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This Jupyter notebook contains all the step-by-step instructions needed for this exercise.\n",
    "1. Write **efficient**, **vectorized** code whenever possible. Some calculations in this exercise may take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deductions.\n",
    "1. You are responsible for the correctness of your code and should add as many tests as you see fit to this jupyter notebook. Tests will not be graded nor checked.\n",
    "1. Complete the required functions in `hw2.py` script only. This exercise is graded automatically, and only the `hw2.py` script is tested.\n",
    "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/), numpy and pandas only. **Do not import anything else.**\n",
    "1. Your code must run without errors. Use at least `numpy` 1.15.4. Any code that cannot run will not be graded.\n",
    "1. Write your own code. Cheating will not be tolerated.\n",
    "1. Submission includes a zip file that contains the `hw2.py` script as well as this notebook, with your ID as the file name. For example, `hw2_123456789_987654321.zip` if you submitted in pairs and `hw2_123456789.zip` if you submitted the exercise alone. \n",
    "\n",
    "Please use only a **zip** file in your submission.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Please sign that you have read and understood the instructions: \n",
    "\n",
    "### *** 323929992 ***\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have read and understood the instructions: *** 323929992 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed9fe7b1026e33cb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make the notebook automatically reload external python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c6ac605270c2b091",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Warmup - OOP in python\n",
    "\n",
    "Our desicion tree will be implemented using a dedicated python class. Python classes are very similar to classes in other object oriented programming languages you might be familiar with.\n",
    "\n",
    "\n",
    "You can use the following [site](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/) to learn about classes in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, node):\n",
    "        self.children.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Node at 0x1ea65a62f50>, <__main__.Node at 0x1ea525f2b10>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Node(5)\n",
    "p = Node(6)\n",
    "q = Node(7)\n",
    "n.add_child(p)\n",
    "n.add_child(q)\n",
    "n.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f1ceb251c649b62",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "For the following exercise, we will use a dataset containing mushroom data `agaricus-lepiota.csv`. \n",
    "\n",
    "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous\n",
    "one (=there are only two classes **edible** and **poisonous**). \n",
    "    \n",
    "The dataset contains 8124 observations with 21 features and the class:\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
    "1. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "1. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "1. bruises: bruises=t,no=f\n",
    "1. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "1. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "1. gill-spacing: close=c,crowded=w,distant=d\n",
    "1. gill-size: broad=b,narrow=n\n",
    "1. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "1. stalk-shape: enlarging=e,tapering=t\n",
    "1. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "1. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "1. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "1. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
    "1. veil-type: partial=p,universal=u\n",
    "1. veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "1. ring-number: none=n,one=o,two=t\n",
    "1. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
    "1. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
    "1. population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
    "1. habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
    "\n",
    "First, we will read and explore the data using pandas and the `.read_csv` method. Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d79cb4542926ad3f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cap-shape cap-surface cap-color bruises odor gill-attachment   \n",
       "0            x           s         n       t    p               f  \\\n",
       "1            x           s         y       t    a               f   \n",
       "2            b           s         w       t    l               f   \n",
       "3            x           y         w       t    p               f   \n",
       "4            x           s         g       f    n               f   \n",
       "...        ...         ...       ...     ...  ...             ...   \n",
       "8119         k           s         n       f    n               a   \n",
       "8120         x           s         n       f    n               a   \n",
       "8121         f           s         n       f    n               a   \n",
       "8122         k           y         n       f    y               f   \n",
       "8123         x           s         n       f    n               a   \n",
       "\n",
       "     gill-spacing gill-size gill-color stalk-shape  ...   \n",
       "0               c         n          k           e  ...  \\\n",
       "1               c         b          k           e  ...   \n",
       "2               c         b          n           e  ...   \n",
       "3               c         n          n           e  ...   \n",
       "4               w         b          k           t  ...   \n",
       "...           ...       ...        ...         ...  ...   \n",
       "8119            c         b          y           e  ...   \n",
       "8120            c         b          y           e  ...   \n",
       "8121            c         b          n           e  ...   \n",
       "8122            c         n          b           t  ...   \n",
       "8123            c         b          y           e  ...   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color   \n",
       "0                         w                      w         p          w  \\\n",
       "1                         w                      w         p          w   \n",
       "2                         w                      w         p          w   \n",
       "3                         w                      w         p          w   \n",
       "4                         w                      w         p          w   \n",
       "...                     ...                    ...       ...        ...   \n",
       "8119                      o                      o         p          o   \n",
       "8120                      o                      o         p          n   \n",
       "8121                      o                      o         p          o   \n",
       "8122                      w                      w         p          w   \n",
       "8123                      o                      o         p          o   \n",
       "\n",
       "     ring-number ring-type spore-print-color population habitat class  \n",
       "0              o         p                 k          s       u     p  \n",
       "1              o         p                 n          n       g     e  \n",
       "2              o         p                 n          n       m     e  \n",
       "3              o         p                 k          s       u     p  \n",
       "4              o         e                 n          a       g     e  \n",
       "...          ...       ...               ...        ...     ...   ...  \n",
       "8119           o         p                 b          c       l     e  \n",
       "8120           o         p                 b          v       l     e  \n",
       "8121           o         p                 b          c       l     e  \n",
       "8122           o         e                 w          v       l     p  \n",
       "8123           o         p                 o          c       l     p  \n",
       "\n",
       "[8124 rows x 22 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('agaricus-lepiota.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of the Decision Tree algorithm is that almost no preprocessing is required. However, finding missing values is always required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset to `training` and `test` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (6093, 22)\n",
      "Testing dataset shape:  (2031, 22)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Making sure the last column will hold the labels\n",
    "X, y = data.drop('class', axis=1), data['class']\n",
    "X = np.column_stack([X,y])\n",
    "# split dataset using random_state to get the same split each time\n",
    "X_train, X_test = train_test_split(X, random_state=99)\n",
    "\n",
    "print(\"Training dataset shape: \", X_train.shape)\n",
    "print(\"Testing dataset shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd7b0191f3f1e897",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Impurity Measures (10 points)\n",
    "\n",
    "Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Implement the functions `calc_gini` and `calc_entropy` in `hw2.py`. You are encouraged to test your implementation according to the expected behavior of those measures as seen in class. (5 points each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2 import calc_gini, calc_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49956363223797745, 0.9993703627906086)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your tests here #####\n",
    "\n",
    "calc_gini(X), calc_entropy(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of Split (10 Points)\n",
    "\n",
    "Given some feature, the Goodnees of Split measures the reduction in the impurity if we split the data according to the feature.\n",
    "$$\n",
    "\\Delta\\varphi(S, A) = \\varphi(S) - \\sum_{v\\in Values(A)} \\frac{|S_v|}{|S|}\\varphi(S_v)\n",
    "$$\n",
    "\n",
    "In our implementation the goodness_of_split function will return either the Goodness of Split or the Gain Ratio as learned in class. You'll control the return value with the `gain_ratio` parameter. If this parameter will set to False (the default value) it will return the regular Goodness of Split. If it will set to True it will return the Gain Ratio.\n",
    "$$\n",
    "GainRatio(S,A)=\\frac{InformationGain(S,A)}{SplitInformation(S,A)}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "InformationGain(S,A)=Goodness\\ of\\ Split\\ calculated\\ with\\ Entropy\\ as\\ the\\ Impurity\\ function \\\\\n",
    "SplitInformation(S,A)=- \\sum_{a\\in A} \\frac{|S_a|}{|S|}\\log\\frac{|S_a|}{|S|}\n",
    "$$\n",
    "\n",
    "Implement the function `goodness_of_split` in `hw2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2 import goodness_of_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01995965783444209, 0.030727291723502526)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your tests here #####\n",
    "\n",
    "# python support passing a function as arguments to another function.\n",
    "\n",
    "goodness_gini, split_values_gini = goodness_of_split(X, 0, calc_gini)\n",
    "goodness_entropy, split_values_entropy = goodness_of_split(X, 0, calc_entropy)\n",
    "\n",
    "goodness_gini, goodness_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Decision Tree (35 points)\n",
    "\n",
    "Implement the class `DecisionNode` in `hw2.py`.\n",
    "\n",
    "Use a Python class to construct the decision tree. Your class should support the following functionality:\n",
    "\n",
    "1. Initiating a node for a decision tree. You will need to use several class methods and class attributes that appear in `hw2.py`. \n",
    "1. Note the following attributes and methods for each node:\n",
    "    1. `self.data` holds the relevant data to split that node (ndarray).\n",
    "    1. `self.feature` holds the best feature that splits the node (int).\n",
    "    1. `self.pred` holds the prediction of the entire node (string).\n",
    "    1. `self.depth` holds the depth of the node (int).\n",
    "    1. `self.children` holds the objects of the children of the node (list).\n",
    "    1. `self.children_values` holds the value of the feature associated with the children (list).\n",
    "    1. `self.terminal` determines if the node is a leaf (boolean).\n",
    "    1. `self.chi` holds the chi square value (int).\n",
    "    1. `self.max_depth` holds the maximum allowed depth of the entire tree (int).\n",
    "    1. `self.gain_ratio` determines if gain_ratio is used (boolean).\n",
    "\n",
    "1. Your code should support both Gini and Entropy as impurity measures. \n",
    "1. The provided data includes categorical data. In this exercise, when splitting a node create the number of children needed according to the attribute unique values.\n",
    "1. Complete the class `DecisionNode`. Implementation details are up to you, but maintain the function signature and outputs. Make sure you are not changing the provided functions / variables we provided.\n",
    "1. You can create auxiliary functions, methods and variables.\n",
    "1. Complete the function `build_tree`. This function should get the training dataset and the impurity as inputs, initiate a root for the decision tree and construct the tree according to the procedure you learned in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2 import build_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x' 's' 'y' 't' 'l' 'f' 'c' 'b' 'w' 'e' 's' 's' 'w' 'w' 'p' 'w' 'o' 'p'\n",
      " 'n' 'n' 'g' 'e']\n"
     ]
    }
   ],
   "source": [
    "##### Your tests here #####\n",
    "print(X_train[0, :])\n",
    "tree_gini = build_tree(data=X_train, impurity=calc_gini) # gini and goodness of split\n",
    "tree_entropy = build_tree(data=X_train, impurity=calc_entropy) # entropy and goodness of split\n",
    "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True) # entropy and gain ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree evaluation (10 points) \n",
    "\n",
    "Implement the functions `predict` and `calc_accuracy` in `hw2.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2 import calc_accuracy, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the three trees using the training set, you should calculate the accuracy on the test set. For each tree print the training and test accuracy. Select the tree that gave you the best test accuracy. For the rest of the exercise, use that tree (when you asked to build another tree use the same impurity function and same gain_ratio flag). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini 1.0 1.0\n",
      "entropy 1.0 1.0\n",
      "entropy gain ratio 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "##### Your tests here #####\n",
    "\n",
    "print('gini', calc_accuracy(tree_gini, X_train), calc_accuracy(tree_gini, X_test))\n",
    "print('entropy', calc_accuracy(tree_entropy, X_train), calc_accuracy(tree_entropy, X_test))\n",
    "print('entropy gain ratio', calc_accuracy(tree_entropy_gain_ratio, X_train), \n",
    "      calc_accuracy(tree_entropy_gain_ratio, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth pruning (15 points)\n",
    "\n",
    "In this part, we will investigate the effect the max depth of the tree has on the training and testing accuracies.\n",
    "\n",
    "For each max_depth value in the range [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], construct a tree and prune it according to the max_depth value (don't let the tree to grow beyond this depth). Next, calculate the training and testing accuracy on the resulting trees. \n",
    "\n",
    "In order to debug and self-test your code, draw the training and testing accuracy as a function of the max_depth and verify that your results make sense. The red dot denotes the best model according to the testing accuracy.\n",
    "\n",
    "Implement the function `depth_pruning` in `hw2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ea684a10d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Your tests here #####\n",
    "from hw2 import depth_pruning\n",
    "depth_training_acc, depth_testing_acc = depth_pruning(X_train, X_test)\n",
    "\n",
    "plt.plot(range(1, 11), depth_training_acc, label='Training')\n",
    "plt.plot(range(1, 11), depth_testing_acc, label='Test')\n",
    "plt.scatter(np.argmax(depth_testing_acc)+1, max(depth_testing_acc), c='r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi square pre-pruning (15 points)\n",
    "\n",
    "Consider the following p-value cut-off values: [1 (no pruning), 0.5, 0.25, 0.1, 0.05, 0.0001 (max pruning)]. For each value, construct a tree and prune it according to the cut-off value. Next, calculate the training and testing accuracy on the resulting trees. \n",
    "\n",
    "In order to debug and self-test your code, draw the training and testing accuracy as a function of the tuple (p-value, tree depth) and verify that your results make sense. The red dot denotes the best model according to the testing accuracy.\n",
    "\n",
    "Implement the function `chi_pruning` in `hw2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2 import chi_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Your tests here #####\n",
    "\n",
    "chi_training_acc, chi_testing_acc, depth = chi_pruning(X_train, X_test)\n",
    "\n",
    "chi_depth_tuple = [str((x, y)) for x, y in zip([1, 0.5, 0.25, 0.1, 0.05, 0.0001], depth)][::-1]\n",
    "plt.plot(chi_depth_tuple, chi_training_acc[::-1], label='Training')\n",
    "plt.plot(chi_depth_tuple, chi_testing_acc[::-1], label='Test')\n",
    "plt.scatter(chi_depth_tuple[np.argmax(chi_testing_acc[::-1])], max(chi_testing_acc), c='r')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the best 2 trees:\n",
    "1. tree_max_depth - the best tree according to max_depth pruning\n",
    "1. tree_chi - the best tree according to chi square pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_max_depth = None\n",
    "tree_chi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Nodes (5 points) \n",
    "\n",
    "Of the two trees above we will choose the one with fewer nodes.\n",
    "\n",
    "Complete the function counts_nodes and print the number of nodes in each tree\n",
    "\n",
    "Implement the function `count_nodes` in `hw2.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw2 import count_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Your tests here #####\n",
    "\n",
    "print(count_nodes(tree_max_depth))\n",
    "print(count_nodes(tree_chi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the tree\n",
    "\n",
    "We provided you with a function that should print your tree for your own debugging purposes. \n",
    "\n",
    "This code prints:\n",
    "```\n",
    "[ROOT, feature=X0],\n",
    "  [X0=a, feature=X2]\n",
    "    [X2=c, leaf]: [{1.0: 10}]\n",
    "    [X2=d, leaf]: [{0.0: 10}]\n",
    "  [X0=y, feature=X5], \n",
    "       [X5=a, leaf]: [{1.0: 5}]\n",
    "       [X5=s, leaf]: [{0.0: 10}]\n",
    "  [X0=e, leaf]: [{0.0: 25, 1.0: 50}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0, parent_feature='ROOT', feature_val='ROOT'):\n",
    "    '''\n",
    "    prints the tree according to the example above\n",
    "\n",
    "    Input:\n",
    "    - node: a node in the decision tree\n",
    "\n",
    "    This function has no return value\n",
    "    '''\n",
    "    if node.terminal == False:\n",
    "        if node.depth == 0:\n",
    "            print('[ROOT, feature=X{}]'.format(node.feature))\n",
    "        else:\n",
    "            print('{}[X{}={}, feature=X{}], Depth: {}'.format(depth*'  ', parent_feature, feature_val, \n",
    "                                                              node.feature, node.depth))\n",
    "        for i, child in enumerate(node.children):\n",
    "            print_tree(child, depth+1, node.feature, node.children_values[i])\n",
    "    else:\n",
    "        classes_count = {}\n",
    "        labels, counts = np.unique(node.data[:, -1], return_counts=True)\n",
    "        for l, c in zip(labels, counts):\n",
    "            classes_count[l] = c\n",
    "        print('{}[X{}={}, leaf]: [{}], Depth: {}'.format(depth*'  ', parent_feature, feature_val,\n",
    "                                                         classes_count, node.depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(tree_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
